{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":4673033,"sourceType":"datasetVersion","datasetId":2709896}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom transformers import DefaultDataCollator\nfrom sklearn.model_selection import train_test_split\nfrom datasets import load_dataset, Dataset, DatasetDict, concatenate_datasets\nfrom transformers import AutoTokenizer, AutoModelForQuestionAnswering, AutoModelForCausalLM, AutoModelForSeq2SeqLM\nfrom transformers import TrainingArguments, Trainer","metadata":{"execution":{"iopub.status.busy":"2024-04-27T17:04:27.172135Z","iopub.execute_input":"2024-04-27T17:04:27.173402Z","iopub.status.idle":"2024-04-27T17:04:27.178645Z","shell.execute_reply.started":"2024-04-27T17:04:27.173363Z","shell.execute_reply":"2024-04-27T17:04:27.177663Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"if torch.cuda.is_available():\n    device = \"cuda\"\n    print(\"cuda\")\nelse:\n    device = \"cpu\"\n    print(\"cpu\")","metadata":{"execution":{"iopub.status.busy":"2024-04-27T17:04:29.287747Z","iopub.execute_input":"2024-04-27T17:04:29.288501Z","iopub.status.idle":"2024-04-27T17:04:29.323098Z","shell.execute_reply.started":"2024-04-27T17:04:29.288445Z","shell.execute_reply":"2024-04-27T17:04:29.322081Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"cuda\n","output_type":"stream"}]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(\"riotu-lab/ArabianGPT-01B\")\nmodel = AutoModelForCausalLM.from_pretrained(\"riotu-lab/ArabianGPT-01B\").to(device)\nmodelQA = AutoModelForQuestionAnswering.from_pretrained(\"riotu-lab/ArabianGPT-01B\").to(device)","metadata":{"execution":{"iopub.status.busy":"2024-04-27T17:05:38.736920Z","iopub.execute_input":"2024-04-27T17:05:38.737308Z","iopub.status.idle":"2024-04-27T17:05:44.391117Z","shell.execute_reply.started":"2024-04-27T17:05:38.737276Z","shell.execute_reply":"2024-04-27T17:05:44.390307Z"},"trusted":true},"execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/106 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"880aa4c4df8b40abab0679c512c216e2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/3.42M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e0eca09b5e19420a8daf0109bd7faf19"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/51.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f40c1eb3a2d646f3a7294a7c83baa867"}},"metadata":{}},{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/904 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6172d4b9b501456d9a33c7fabfea456e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/546M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5459676f3dbf445bb38612038c72f6d3"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n  return self.fget.__get__(instance, owner)()\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/94.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d5669e7926284ad5a89b396dc19541b1"}},"metadata":{}},{"name":"stderr","text":"Some weights of GPT2ForQuestionAnswering were not initialized from the model checkpoint at riotu-lab/ArabianGPT-01B and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"# Example prompt\nprompt = \"ان تكون أو لا تكون\"\n\n# Tokenize input\ninput_ids = tokenizer.encode(prompt, return_tensors=\"pt\").to(device)\n\noutput = model.generate(\n    input_ids,\n    max_length=100,\n    temperature=0.7,\n    do_sample=True\n)\n\n# Decode and print generated text\ngenerated_text = tokenizer.decode(output[0])\nprint(generated_text)","metadata":{"execution":{"iopub.status.busy":"2024-04-27T14:22:14.256545Z","iopub.execute_input":"2024-04-27T14:22:14.256938Z","iopub.status.idle":"2024-04-27T14:22:15.351456Z","shell.execute_reply.started":"2024-04-27T14:22:14.256906Z","shell.execute_reply":"2024-04-27T14:22:15.350388Z"},"trusted":true},"execution_count":228,"outputs":[{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:64000 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"ان تكون أو لا تكون قد سبق لها الحصول على إجازة دراسية من احدى الجامعات أو إحدى الجامعات السعودية.. الخ.. إلخ.. الخ.. وأن تكون قد مضى على حصولها على دبلوم المعاهد الفنية ثلاث سنوات على الأقل.. وأن يتم تحديد مدة الدراسة في المعاهد الفنية التجارية التابعة لإدارة التربية والتعليم بالمحافظة وفقا لنظام التعليم الفني والتدريب المهني.. وأن لا تقل عن ثلاث سنوات.. وأن لا تقل في مدة الدراسة عن ست سنوات.. وأن لا تقل في مدة الدراسة عن ست سنوات.. وأن لا\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Data Exploring","metadata":{}},{"cell_type":"code","source":"original_dataset = load_dataset(\"arcd\")","metadata":{"execution":{"iopub.status.busy":"2024-04-27T17:04:39.142241Z","iopub.execute_input":"2024-04-27T17:04:39.143150Z","iopub.status.idle":"2024-04-27T17:04:43.581818Z","shell.execute_reply.started":"2024-04-27T17:04:39.143117Z","shell.execute_reply":"2024-04-27T17:04:43.580935Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading readme:   0%|          | 0.00/8.53k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4ebdc959c5a74570afe9fce8c8837377"}},"metadata":{}},{"name":"stderr","text":"Downloading data: 100%|██████████| 174k/174k [00:00<00:00, 1.09MB/s]\nDownloading data: 100%|██████████| 192k/192k [00:00<00:00, 1.89MB/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/693 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c2ae9429f0404a22b4ecf1aab17d661d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/702 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"33c46ee961d94d359e3d6a7dced83b35"}},"metadata":{}}]},{"cell_type":"code","source":"print(original_dataset)","metadata":{"execution":{"iopub.status.busy":"2024-04-27T17:04:46.224398Z","iopub.execute_input":"2024-04-27T17:04:46.225371Z","iopub.status.idle":"2024-04-27T17:04:46.230047Z","shell.execute_reply.started":"2024-04-27T17:04:46.225337Z","shell.execute_reply":"2024-04-27T17:04:46.229035Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"DatasetDict({\n    train: Dataset({\n        features: ['id', 'title', 'context', 'question', 'answers'],\n        num_rows: 693\n    })\n    validation: Dataset({\n        features: ['id', 'title', 'context', 'question', 'answers'],\n        num_rows: 702\n    })\n})\n","output_type":"stream"}]},{"cell_type":"code","source":"# Extract the train and validation datasets\ntrain_dataset = original_dataset['train']\nval_dataset = original_dataset['validation']\n\n# Select the first 200 rows for validation\nnew_val_dataset = val_dataset.select(range(100))\n\n# Select the remaining rows for training\nremaining_val_dataset = val_dataset.select(range(100, len(val_dataset)))\n\n\nnew_train_dataset = concatenate_datasets([train_dataset, remaining_val_dataset])\n\n# Create a new DatasetDict with the updated splits\nnew_dataset = DatasetDict({\n    'train': new_train_dataset,\n    'validation': new_val_dataset\n})\n\n# Print the information of the new DatasetDict\nprint(new_dataset)","metadata":{"execution":{"iopub.status.busy":"2024-04-27T17:05:00.987419Z","iopub.execute_input":"2024-04-27T17:05:00.987774Z","iopub.status.idle":"2024-04-27T17:05:01.007179Z","shell.execute_reply.started":"2024-04-27T17:05:00.987744Z","shell.execute_reply":"2024-04-27T17:05:01.006320Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"DatasetDict({\n    train: Dataset({\n        features: ['id', 'title', 'context', 'question', 'answers'],\n        num_rows: 1295\n    })\n    validation: Dataset({\n        features: ['id', 'title', 'context', 'question', 'answers'],\n        num_rows: 100\n    })\n})\n","output_type":"stream"}]},{"cell_type":"code","source":"new_dataset = new_dataset.remove_columns([\"id\", \"title\"])\nprint(new_dataset)","metadata":{"execution":{"iopub.status.busy":"2024-04-27T17:05:17.946322Z","iopub.execute_input":"2024-04-27T17:05:17.946720Z","iopub.status.idle":"2024-04-27T17:05:17.959943Z","shell.execute_reply.started":"2024-04-27T17:05:17.946688Z","shell.execute_reply":"2024-04-27T17:05:17.958711Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"DatasetDict({\n    train: Dataset({\n        features: ['context', 'question', 'answers'],\n        num_rows: 1295\n    })\n    validation: Dataset({\n        features: ['context', 'question', 'answers'],\n        num_rows: 100\n    })\n})\n","output_type":"stream"}]},{"cell_type":"code","source":"def preprocess_function(examples):\n    questions = [q.strip() for q in examples[\"question\"]]\n    inputs = tokenizer(\n        questions,\n        examples[\"context\"],\n        max_length=384,\n        truncation=\"only_second\",\n        return_offsets_mapping=True,\n        padding=\"longest\",\n    )\n\n    offset_mapping = inputs.pop(\"offset_mapping\")\n    answers = examples[\"answers\"]\n    start_positions = []\n    end_positions = []\n\n    for i, offset in enumerate(offset_mapping):\n        answer = answers[i]\n        start_char = answer[\"answer_start\"][0] if answer[\"answer_start\"] else None\n        end_char = start_char + len(answer[\"text\"][0]) if start_char is not None else None\n        sequence_ids = inputs.sequence_ids(i) if inputs.sequence_ids(i) else []\n\n        if not start_char or not end_char or not sequence_ids:\n            # Handle cases where start_char, end_char, or sequence_ids are empty\n            start_positions.append(0)\n            end_positions.append(0)\n            continue  # Move to the next iteration\n\n        idx = 0\n        while idx < len(sequence_ids) and sequence_ids[idx] != 1:\n            idx += 1\n        context_start = idx\n\n        while idx < len(sequence_ids) and sequence_ids[idx] == 1:\n            idx += 1\n        context_end = idx - 1\n\n        if context_start >= len(offset) or context_end >= len(offset):\n            # Handle cases where context indices exceed offset_mapping length\n            start_positions.append(0)\n            end_positions.append(0)\n            continue  # Move to the next iteration\n\n        if offset[context_start][0] > end_char or offset[context_end][1] < start_char:\n            start_positions.append(0)\n            end_positions.append(0)\n        else:\n            idx = context_start\n            while idx <= context_end and offset[idx][0] <= start_char:\n                idx += 1\n            start_positions.append(idx - 1)\n\n            idx = context_end\n            while idx >= context_start and offset[idx][1] >= end_char:\n                idx -= 1\n            end_positions.append(idx + 1)\n\n    inputs[\"start_positions\"] = start_positions\n    inputs[\"end_positions\"] = end_positions\n    return inputs","metadata":{"execution":{"iopub.status.busy":"2024-04-27T17:05:20.358674Z","iopub.execute_input":"2024-04-27T17:05:20.359347Z","iopub.status.idle":"2024-04-27T17:05:20.371936Z","shell.execute_reply.started":"2024-04-27T17:05:20.359307Z","shell.execute_reply":"2024-04-27T17:05:20.370804Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"processed_dataset = new_dataset.map(preprocess_function, batched=True,remove_columns=new_dataset[\"train\"].column_names)","metadata":{"execution":{"iopub.status.busy":"2024-04-27T17:06:09.496813Z","iopub.execute_input":"2024-04-27T17:06:09.497187Z","iopub.status.idle":"2024-04-27T17:06:10.498277Z","shell.execute_reply.started":"2024-04-27T17:06:09.497157Z","shell.execute_reply":"2024-04-27T17:06:10.497319Z"},"trusted":true},"execution_count":13,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1295 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"111a585dda7a46ba8b45ca2c597e266e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/100 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b240c56041ac472899317e629f36d9b6"}},"metadata":{}}]},{"cell_type":"code","source":"print(processed_dataset)","metadata":{"execution":{"iopub.status.busy":"2024-04-27T17:06:12.316324Z","iopub.execute_input":"2024-04-27T17:06:12.316694Z","iopub.status.idle":"2024-04-27T17:06:12.321611Z","shell.execute_reply.started":"2024-04-27T17:06:12.316666Z","shell.execute_reply":"2024-04-27T17:06:12.320474Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"DatasetDict({\n    train: Dataset({\n        features: ['input_ids', 'token_type_ids', 'attention_mask', 'start_positions', 'end_positions'],\n        num_rows: 1295\n    })\n    validation: Dataset({\n        features: ['input_ids', 'token_type_ids', 'attention_mask', 'start_positions', 'end_positions'],\n        num_rows: 100\n    })\n})\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Model Building","metadata":{}},{"cell_type":"code","source":"train_params = TrainingArguments(\n    \n    # Learning algorithms parameters\n    optim = \"paged_adamw_32bit\",\n    learning_rate = 3e-4,\n    weight_decay = 0.01,\n    lr_scheduler_type = 'cosine',\n    \n    # Memory Optimization parameters\n    gradient_accumulation_steps = 4,\n    gradient_checkpointing = True,\n    \n    per_device_train_batch_size = 8,\n    per_device_eval_batch_size = 8,\n    auto_find_batch_size='power_of_two',\n    \n    max_grad_norm=2,\n    group_by_length=True,\n    num_train_epochs=3,\n    \n    output_dir = '/model_outputs',\n    logging_dir=\"./logs\",\n    save_steps = 50,\n    logging_steps = 10,\n    \n    evaluation_strategy = \"steps\",  # Set the evaluation strategy to \"steps\"\n    save_strategy = \"steps\",\n    push_to_hub=True\n)","metadata":{"execution":{"iopub.status.busy":"2024-04-27T17:17:46.316285Z","iopub.execute_input":"2024-04-27T17:17:46.317038Z","iopub.status.idle":"2024-04-27T17:17:46.347048Z","shell.execute_reply.started":"2024-04-27T17:17:46.317002Z","shell.execute_reply":"2024-04-27T17:17:46.346145Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"data_collator = DefaultDataCollator(return_tensors=\"pt\")","metadata":{"execution":{"iopub.status.busy":"2024-04-27T17:17:48.470327Z","iopub.execute_input":"2024-04-27T17:17:48.470978Z","iopub.status.idle":"2024-04-27T17:17:48.476135Z","shell.execute_reply.started":"2024-04-27T17:17:48.470941Z","shell.execute_reply":"2024-04-27T17:17:48.475039Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"trainer = Trainer(\n    model=modelQA,\n    args=train_params,\n    train_dataset=processed_dataset[\"train\"],\n    eval_dataset=processed_dataset[\"validation\"],\n    data_collator=data_collator,\n    tokenizer=tokenizer,\n)","metadata":{"execution":{"iopub.status.busy":"2024-04-27T14:30:03.976767Z","iopub.execute_input":"2024-04-27T14:30:03.977464Z","iopub.status.idle":"2024-04-27T14:30:03.995390Z","shell.execute_reply.started":"2024-04-27T14:30:03.977425Z","shell.execute_reply":"2024-04-27T14:30:03.994162Z"},"trusted":true},"execution_count":242,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \ndataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-04-27T14:30:05.149644Z","iopub.execute_input":"2024-04-27T14:30:05.150236Z","iopub.status.idle":"2024-04-27T14:34:27.831647Z","shell.execute_reply.started":"2024-04-27T14:30:05.150203Z","shell.execute_reply":"2024-04-27T14:34:27.830779Z"},"trusted":true},"execution_count":243,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='117' max='117' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [117/117 04:16, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>10</td>\n      <td>1.842200</td>\n      <td>3.557961</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>1.622500</td>\n      <td>3.497063</td>\n    </tr>\n    <tr>\n      <td>30</td>\n      <td>1.289700</td>\n      <td>3.732351</td>\n    </tr>\n    <tr>\n      <td>40</td>\n      <td>1.385500</td>\n      <td>3.406400</td>\n    </tr>\n    <tr>\n      <td>50</td>\n      <td>0.647000</td>\n      <td>4.031374</td>\n    </tr>\n    <tr>\n      <td>60</td>\n      <td>1.130500</td>\n      <td>3.619244</td>\n    </tr>\n    <tr>\n      <td>70</td>\n      <td>0.914300</td>\n      <td>3.592458</td>\n    </tr>\n    <tr>\n      <td>80</td>\n      <td>0.878400</td>\n      <td>3.568894</td>\n    </tr>\n    <tr>\n      <td>90</td>\n      <td>0.397200</td>\n      <td>3.691824</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>0.345500</td>\n      <td>3.762138</td>\n    </tr>\n    <tr>\n      <td>110</td>\n      <td>0.338600</td>\n      <td>3.783069</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n","output_type":"stream"},{"execution_count":243,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=117, training_loss=0.9433518699091724, metrics={'train_runtime': 259.0401, 'train_samples_per_second': 14.419, 'train_steps_per_second': 0.452, 'total_flos': 731957539806720.0, 'train_loss': 0.9433518699091724, 'epoch': 3.0})"},"metadata":{}}]},{"cell_type":"code","source":"trainer.save_model(\"/kaggle/working/final_model\")","metadata":{"execution":{"iopub.status.busy":"2024-04-27T14:50:55.086571Z","iopub.execute_input":"2024-04-27T14:50:55.086924Z","iopub.status.idle":"2024-04-27T14:50:55.912248Z","shell.execute_reply.started":"2024-04-27T14:50:55.086895Z","shell.execute_reply":"2024-04-27T14:50:55.911176Z"},"trusted":true},"execution_count":248,"outputs":[]},{"cell_type":"code","source":"final_model = AutoModelForQuestionAnswering.from_pretrained(\"/kaggle/working/final_model/\")","metadata":{"execution":{"iopub.status.busy":"2024-04-27T15:41:08.170189Z","iopub.execute_input":"2024-04-27T15:41:08.170565Z","iopub.status.idle":"2024-04-27T15:41:08.385665Z","shell.execute_reply.started":"2024-04-27T15:41:08.170533Z","shell.execute_reply":"2024-04-27T15:41:08.384681Z"},"trusted":true},"execution_count":275,"outputs":[]},{"cell_type":"code","source":"def answer_question(context, question):\n\n  # Preprocess the context and question\n  inputs = tokenizer(\n    question,\n    context,\n    max_length=384,\n    truncation=\"only_second\",\n    return_tensors=\"pt\",\n    )\n\n  # Generate the answer using the model\n  outputs = final_model(**inputs)\n  start_logits = outputs.start_logits\n  end_logits = outputs.end_logits\n\n  \n  answer_start = torch.argmax(start_logits, dim=-1).item()\n  answer_end = torch.argmax(end_logits, dim=-1).item()\n\n  answer = tokenizer.decode(inputs.input_ids[0][answer_start:answer_end + 1])\n  return answer\n\n# Example usage\ndef answer_question(context, question):\n\n  # Preprocess the context and question\n  inputs = tokenizer(\n    question,\n    context,\n    max_length=384,\n    truncation=\"only_second\",\n    return_tensors=\"pt\",\n    )\n\n  # Generate the answer using the model\n  outputs = final_model(**inputs)\n  start_logits = outputs.start_logits\n  end_logits = outputs.end_logits\n\n  \n  answer_start = torch.argmax(start_logits, dim=-1).item()\n  answer_end = torch.argmax(end_logits, dim=-1).item()\n\n  answer = tokenizer.decode(inputs.input_ids[0][answer_start:answer_end + 1])\n  return answer\n\n# Example usage\ncontext = \"تتأثر الألياف العصبية الطويلة بدرجة أكبر من الألياف العصبية القصيرة، وذلك لأن سرعة التوصيل في العصب تنقص في تناسب مع طول العصب. في هذه المتلازمة، يحدث انخفاض في الإحساس وفقدان ردود الفعل في أصابع كل قدم، وتمتد بعد ذلك إلى أعلى. وعادة ما توصف باحساس الخدر وفقدان الإحساس وعسر اللمس (انخفاض أو فقدان الإحساس في جزء من الجسم) وألم ليلي فيما يشبه القفاز والجورب. ويمكن أن يكون الألم في هيئة حرقان أو وخز أو ألم غير محدد. ويكون الاحساس بوخز الدبابيس والإبر أمراً شائعاً. ويتأثر الاحساس بوضع أعضاء الجسم لبعضها proprioception مبكرا. ولا يمكن لهؤلاء المرضى الشعور عندما يدوسون على جسم غريب كالشظية، أو عندما يتكون لهم جلد صلب من الأحذية الضيقة. وبناء على ذلك، فإنهم معرضون لخطر حدوث القرحة والتهابات القدمين والساقين، والتي يمكن أن تؤدي إلى البتر وقد يحدث لهؤلاء المرضى كسورا متعددة في الركبة أو الكاحل أو القدم وقد تؤدي إلى حدوث انحلال في المفاصل. ويؤدي فقدان وظيفة الحركة إلى تقوس القدم لأعلى dorsiflexion، وتقلص أصابع القدم وفقدان وظيفة العضلات بين الأصابع، مما يسمى بالقدم المطرقة. ولا تقتصر هذه التقلصات على القدم فقط، بل أيضا تصيب اليد حيث فقدان العضلات يجعل اليد تبدو هزيلة كالهيكل العظمي ويزداد فقدان الوظيفة الحركية\"\nquestion = \"ما هي العوامل التي تؤثر على سرعة الموصلات العصبية؟\"\n\npredicted_answer = answer_question(context, question)\nprint(f\"Predicted Answer: {predicted_answer}\")","metadata":{"execution":{"iopub.status.busy":"2024-04-27T16:56:05.053661Z","iopub.execute_input":"2024-04-27T16:56:05.054304Z","iopub.status.idle":"2024-04-27T16:56:05.424425Z","shell.execute_reply.started":"2024-04-27T16:56:05.054269Z","shell.execute_reply":"2024-04-27T16:56:05.422434Z"},"trusted":true},"execution_count":320,"outputs":[{"name":"stdout","text":"Predicted Answer: سرعة التوصيل في العصب تنقص في تناسب مع طول العصب.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# ArabianGPT 0.3B","metadata":{}},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(\"riotu-lab/ArabianGPT-03B\")\nmodel = AutoModelForCausalLM.from_pretrained(\"riotu-lab/ArabianGPT-03B\").to(device)\nmodelQA = AutoModelForQuestionAnswering.from_pretrained(\"riotu-lab/ArabianGPT-03B\").to(device)","metadata":{"execution":{"iopub.status.busy":"2024-04-27T17:18:04.213086Z","iopub.execute_input":"2024-04-27T17:18:04.213463Z","iopub.status.idle":"2024-04-27T17:18:06.803076Z","shell.execute_reply.started":"2024-04-27T17:18:04.213434Z","shell.execute_reply":"2024-04-27T17:18:06.801941Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\nSome weights of GPT2ForQuestionAnswering were not initialized from the model checkpoint at riotu-lab/ArabianGPT-03B and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"# Example prompt\nprompt = \"ان تكون أو لا تكون\"\n\n# Tokenize input\ninput_ids = tokenizer.encode(prompt, return_tensors=\"pt\").to(device)\n\noutput = model.generate(\n    input_ids,\n    max_length=100,\n    temperature=0.8,\n    do_sample=True\n)\n\n# Decode and print generated text\ngenerated_text = tokenizer.decode(output[0])\nprint(generated_text)","metadata":{"execution":{"iopub.status.busy":"2024-04-27T16:58:23.579792Z","iopub.execute_input":"2024-04-27T16:58:23.580160Z","iopub.status.idle":"2024-04-27T16:58:25.603178Z","shell.execute_reply.started":"2024-04-27T16:58:23.580131Z","shell.execute_reply":"2024-04-27T16:58:25.602304Z"},"trusted":true},"execution_count":333,"outputs":[{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:64000 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"ان تكون أو لا تكون.. انا وانت.. لا ادري.. ؟!!.. لكن هذا هو الواقع.. ؟!!.. هل نحن على الطريق الصحيح لنرتقي ونتقدم ونصل الى ما نصبوا اليه ؟!!.. اما ان نكون مجرد اوراق في مهب الريح..!!.. نعم.. اننا على طريق الضياع.. الضياع.. الضياع الذي لا نعرف ماذا نريد.. ما نريده فقط هو ان نكون مجرد أوراق.. اوراق..\n","output_type":"stream"}]},{"cell_type":"code","source":"trainer = Trainer(\n    model=modelQA,\n    args=train_params,\n    train_dataset=processed_dataset[\"train\"],\n    eval_dataset=processed_dataset[\"validation\"],\n    data_collator=data_collator,\n    tokenizer=tokenizer,\n)","metadata":{"execution":{"iopub.status.busy":"2024-04-27T17:18:15.194776Z","iopub.execute_input":"2024-04-27T17:18:15.195555Z","iopub.status.idle":"2024-04-27T17:18:15.300916Z","shell.execute_reply.started":"2024-04-27T17:18:15.195523Z","shell.execute_reply":"2024-04-27T17:18:15.299941Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-04-27T17:18:18.604464Z","iopub.execute_input":"2024-04-27T17:18:18.605168Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='84' max='120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [ 84/120 08:43 < 03:49, 0.16 it/s, Epoch 2.05/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>10</td>\n      <td>6.451500</td>\n      <td>4.585489</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>4.891200</td>\n      <td>4.160758</td>\n    </tr>\n    <tr>\n      <td>30</td>\n      <td>4.352400</td>\n      <td>4.050859</td>\n    </tr>\n    <tr>\n      <td>40</td>\n      <td>4.153700</td>\n      <td>4.048408</td>\n    </tr>\n    <tr>\n      <td>50</td>\n      <td>3.671600</td>\n      <td>4.021072</td>\n    </tr>\n    <tr>\n      <td>60</td>\n      <td>3.428400</td>\n      <td>4.135720</td>\n    </tr>\n    <tr>\n      <td>70</td>\n      <td>3.521500</td>\n      <td>4.252016</td>\n    </tr>\n    <tr>\n      <td>80</td>\n      <td>3.433600</td>\n      <td>4.027042</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"trainer.save_model(\"/kaggle/working/final_model_03\")","metadata":{"execution":{"iopub.status.busy":"2024-04-27T16:43:18.755216Z","iopub.execute_input":"2024-04-27T16:43:18.755910Z","iopub.status.idle":"2024-04-27T16:44:09.763178Z","shell.execute_reply.started":"2024-04-27T16:43:18.755874Z","shell.execute_reply":"2024-04-27T16:44:09.762003Z"},"trusted":true},"execution_count":300,"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.48G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d0e6bfd1e7fd4f70a1e4a625840021fe"}},"metadata":{}}]},{"cell_type":"code","source":"final_model_03 = AutoModelForQuestionAnswering.from_pretrained(\"/kaggle/working/final_model_0.3\")","metadata":{"execution":{"iopub.status.busy":"2024-04-27T16:55:13.336505Z","iopub.execute_input":"2024-04-27T16:55:13.336852Z","iopub.status.idle":"2024-04-27T16:55:14.064693Z","shell.execute_reply.started":"2024-04-27T16:55:13.336825Z","shell.execute_reply":"2024-04-27T16:55:14.062923Z"},"trusted":true},"execution_count":317,"outputs":[]},{"cell_type":"code","source":"def answer_question(context, question):\n\n  # Preprocess the context and question\n  inputs = tokenizer(\n    question,\n    context,\n    max_length=384,\n    truncation=\"only_second\",\n    return_tensors=\"pt\",\n    )\n\n  # Generate the answer using the model\n  outputs = final_model_03(**inputs)\n  start_logits = outputs.start_logits\n  end_logits = outputs.end_logits\n\n  \n  answer_start = torch.argmax(start_logits, dim=-1).item()\n  answer_end = torch.argmax(end_logits, dim=-1).item()\n\n  answer = tokenizer.decode(inputs.input_ids[0][answer_start:answer_end + 1])\n  return answer\n\n# Example usage\ncontext = \"تتأثر الألياف العصبية الطويلة بدرجة أكبر من الألياف العصبية القصيرة، وذلك لأن سرعة التوصيل في العصب تنقص في تناسب مع طول العصب. في هذه المتلازمة، يحدث انخفاض في الإحساس وفقدان ردود الفعل في أصابع كل قدم، وتمتد بعد ذلك إلى أعلى. وعادة ما توصف باحساس الخدر وفقدان الإحساس وعسر اللمس (انخفاض أو فقدان الإحساس في جزء من الجسم) وألم ليلي فيما يشبه القفاز والجورب. ويمكن أن يكون الألم في هيئة حرقان أو وخز أو ألم غير محدد. ويكون الاحساس بوخز الدبابيس والإبر أمراً شائعاً. ويتأثر الاحساس بوضع أعضاء الجسم لبعضها proprioception مبكرا. ولا يمكن لهؤلاء المرضى الشعور عندما يدوسون على جسم غريب كالشظية، أو عندما يتكون لهم جلد صلب من الأحذية الضيقة. وبناء على ذلك، فإنهم معرضون لخطر حدوث القرحة والتهابات القدمين والساقين، والتي يمكن أن تؤدي إلى البتر وقد يحدث لهؤلاء المرضى كسورا متعددة في الركبة أو الكاحل أو القدم وقد تؤدي إلى حدوث انحلال في المفاصل. ويؤدي فقدان وظيفة الحركة إلى تقوس القدم لأعلى dorsiflexion، وتقلص أصابع القدم وفقدان وظيفة العضلات بين الأصابع، مما يسمى بالقدم المطرقة. ولا تقتصر هذه التقلصات على القدم فقط، بل أيضا تصيب اليد حيث فقدان العضلات يجعل اليد تبدو هزيلة كالهيكل العظمي ويزداد فقدان الوظيفة الحركية\"\nquestion = \"ما هي العوامل التي تؤثر على سرعة الموصلات العصبية؟\"\n\npredicted_answer = answer_question(context, question)\nprint(f\"Predicted Answer: {predicted_answer}\")","metadata":{"execution":{"iopub.status.busy":"2024-04-27T16:55:24.965336Z","iopub.execute_input":"2024-04-27T16:55:24.966231Z","iopub.status.idle":"2024-04-27T16:55:26.011140Z","shell.execute_reply.started":"2024-04-27T16:55:24.966196Z","shell.execute_reply":"2024-04-27T16:55:26.010165Z"},"trusted":true},"execution_count":318,"outputs":[{"name":"stdout","text":"Predicted Answer: سرعة التوصيل في العصب تنقص في تناسب مع طول العصب.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Generative QA Experiement","metadata":{}},{"cell_type":"code","source":"final_model_03_gen = AutoModelForCausalLM.from_pretrained(\"/kaggle/working/final_model_0.3\")\nfinal_model_gen = AutoModelForCausalLM.from_pretrained(\"/kaggle/working/final_model\")","metadata":{"execution":{"iopub.status.busy":"2024-04-27T15:53:48.671949Z","iopub.execute_input":"2024-04-27T15:53:48.672626Z","iopub.status.idle":"2024-04-27T15:53:49.641204Z","shell.execute_reply.started":"2024-04-27T15:53:48.672590Z","shell.execute_reply":"2024-04-27T15:53:49.640100Z"},"trusted":true},"execution_count":288,"outputs":[]},{"cell_type":"code","source":"# Example question without context\nquestion = \"من هو جمال خاشقجي\"\n\n# Prepare the prompt (adjust as needed)\nprompt = f\"Question: {question} \\n Answer: \"\n\n# Tokenize the prompt\ninput_ids = tokenizer(prompt, return_tensors=\"pt\")[\"input_ids\"]\n\n# Generate the answer using the model (adjust parameters like max_length)\nwith torch.no_grad():\n    outputs = final_model_gen.generate(\n        input_ids=input_ids,\n        max_length=128,\n        early_stopping=True,\n        temperature=0.8,\n        do_sample=True\n    )\n\n# Decode the generated tokens\nanswer = tokenizer.decode(outputs[0], skip_special_tokens=True)\nprint(f\"Generated Answer: {answer}\")","metadata":{"execution":{"iopub.status.busy":"2024-04-27T15:54:26.091688Z","iopub.execute_input":"2024-04-27T15:54:26.092114Z","iopub.status.idle":"2024-04-27T15:54:30.716491Z","shell.execute_reply.started":"2024-04-27T15:54:26.092080Z","shell.execute_reply":"2024-04-27T15:54:30.715457Z"},"trusted":true},"execution_count":290,"outputs":[{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:64000 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Generated Answer: Question: من هو جمال خاشقجي \n Answer: ديث ).. في هذا الحوار.. عن هذا اللقاء.. ما هي اللقاءات الإعلامية في هذا اللقاء.. ما هي اللقاءات الإعلامية مع جمال خاشقجي ؟.. سؤال عن اللقاء.. هل كان للقاءك مع جمال خاشقجي ان يكون في هذا اللقاء الأخير ؟.. لا استطيع أن اجيب عن هذا السؤال.. ولكن هذا السؤال.. هل كان اللقاء الأخير مع جمال خاشقجي ؟.. اللقاء الأخير معك كان في هذا اللقاء.. هل كان للقاء الأخير أم لكومدارس اللقاء الأخير في اللقاء الأخير ؟.. هل كان اللقاء الأول للقاءاتك\n","output_type":"stream"}]},{"cell_type":"code","source":"from huggingface_hub import notebook_login\n\nnotebook_login()","metadata":{"execution":{"iopub.status.busy":"2024-04-27T17:09:03.366809Z","iopub.execute_input":"2024-04-27T17:09:03.367488Z","iopub.status.idle":"2024-04-27T17:09:03.394441Z","shell.execute_reply.started":"2024-04-27T17:09:03.367457Z","shell.execute_reply":"2024-04-27T17:09:03.393563Z"},"trusted":true},"execution_count":19,"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7ce290a4fff7452190dd7a27dd032a8a"}},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}